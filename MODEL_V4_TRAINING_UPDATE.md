# Model V4 Training Script - Updated for Pre-Extracted Image Features

## âœ… Updates Completed

### 1. **Pre-Extracted Image Features Integration**
- âœ… Loads image features directly from `data/image_features_optimized.npy` (57,603 Ã— 512)
- âœ… Uses `image_metadata.csv` for row alignment verification
- âœ… No image re-extraction - uses cached features
- âœ… Handles missing images (8,098 zero vectors already in numpy array)

### 2. **Data Loading Pipeline**
- âœ… Loads CSV dataset from `data/final_dataset_with_images.csv`
- âœ… Loads pre-extracted image features (512 dimensions after PCA)
- âœ… Verifies alignment using `image_metadata.csv`
- âœ… Ensures dataset rows match image feature rows

### 3. **Feature Engineering**
- âœ… Advanced tabular features (18+ features):
  - Age-based depreciation curves
  - Mileage per year
  - Luxury/premium brand indicators
  - Market segment classification
  - Condition numeric encoding
  - Popular model flags
  - Interaction features
  - Brand popularity

### 4. **Feature Combination**
- âœ… Combines tabular features + image features
- âœ… Total features: ~18 tabular + 512 image = ~530 features
- âœ… Maintains proper alignment throughout

### 5. **Scaling Strategy**
- âœ… Scales ONLY tabular features using `RobustScaler`
- âœ… Keeps image features unchanged (already normalized by PCA)
- âœ… Prevents double-scaling of image features

### 6. **Model Training**
- âœ… Train/test split with `random_state=42`
- âœ… XGBoost with Optuna hyperparameter optimization (50 trials)
- âœ… LightGBM (if available)
- âœ… RandomForest (fallback)
- âœ… Metrics: RÂ², RMSE, MAE, MAPE

### 7. **Model Saving**
- âœ… Saves best model to `models/best_model_v4.pkl`
- âœ… Saves scaler to `models/scaler_v4.pkl`
- âœ… Saves encoders to `models/encoders_v4.pkl`
- âœ… Saves model info to `models/model_v4_info.json`

---

## ðŸ“‹ Key Features

### Row Alignment
- Uses `image_metadata.csv` to verify alignment
- Handles sequential (0..N-1) and non-sequential indices
- Ensures image features match correct car records

### Missing Image Handling
- 8,098 images missing (14%)
- Uses zero vectors already stored in numpy array
- Model learns to handle missing images gracefully

### Feature Scaling
- Tabular features: Scaled with `RobustScaler`
- Image features: Unchanged (already PCA-normalized)
- Prevents information loss from double-scaling

---

## ðŸš€ Usage

### Run Training:
```bash
python train_model_v4_optimized.py
```

### Expected Output:
- Model training logs in `model_training_v4.log`
- Best model saved to `models/best_model_v4.pkl`
- Model info saved to `models/model_v4_info.json`

### Target Metrics:
- **RÂ² â‰¥ 0.85** (85%+ accuracy)
- **RMSE < $5,000**
- **MAE < $3,000**
- **MAPE < 10%**

---

## ðŸ“Š Data Flow

```
1. Load CSV Dataset (57,603 rows)
   â†“
2. Load Image Features (57,603 Ã— 512)
   â†“
3. Verify Alignment (using image_metadata.csv)
   â†“
4. Create Advanced Tabular Features (18+ features)
   â†“
5. Combine Tabular + Image Features (~530 total)
   â†“
6. Train/Test Split (80/20, random_state=42)
   â†“
7. Scale Tabular Features Only
   â†“
8. Train Models (XGBoost, LightGBM, RandomForest)
   â†“
9. Select Best Model
   â†“
10. Save Model + Preprocessors
```

---

## âœ… Verification Checklist

- [x] Loads pre-extracted image features (no re-extraction)
- [x] Proper row alignment using metadata
- [x] Combines tabular + image features correctly
- [x] Scales only numeric features (not image vectors)
- [x] Handles missing images (zero vectors)
- [x] Train/test split with random_state=42
- [x] Saves model + preprocessors
- [x] Prints final metrics

---

## ðŸ“ Notes

1. **No Image Re-Extraction**: The script uses pre-extracted features from `data/image_features_optimized.npy`. This saves ~30-60 minutes per training run.

2. **Alignment Guarantee**: Uses `image_metadata.csv` to ensure image features match the correct car records. The metadata has sequential indices (0..N-1), so alignment is straightforward.

3. **Missing Images**: 8,098 images (14%) are missing. These are already represented as zero vectors in the numpy array, so no special handling needed.

4. **Feature Scaling**: Only tabular features are scaled. Image features are kept unchanged since they're already PCA-normalized.

5. **Model Selection**: The script trains multiple models and selects the best one based on RÂ² score.

---

## ðŸŽ¯ Next Steps

1. **Run Training**: Execute `python train_model_v4_optimized.py`
2. **Monitor Progress**: Check `model_training_v4.log` for training progress
3. **Verify Results**: Check `models/model_v4_info.json` for final metrics
4. **Deploy Model**: Update `core/predict_price.py` to load v4 model

---

## ðŸ“ Files Created/Updated

- âœ… `train_model_v4_optimized.py` - Updated training script
- âœ… `models/best_model_v4.pkl` - Best model (created after training)
- âœ… `models/scaler_v4.pkl` - Feature scaler
- âœ… `models/encoders_v4.pkl` - Label encoders
- âœ… `models/model_v4_info.json` - Model metadata

---

**Status**: âœ… Ready for training!
